{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGg4P9BjqpfVV02If1ozMG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Th4l3s-pr0g/estudo-IA-CC/blob/main/ReconhecimentoImagem2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 1 - importar TensorFlow, que é uma biblioteca da Google que abrange diversas funcionalidades desenvolvidas para a aplicação de Inteligência Artificial."
      ],
      "metadata": {
        "id": "Y_5_UXP3KhzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPq0cA0kMA4v",
        "outputId": "bea9f4ce-03dd-4053-dc3e-a51fa8fc71eb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 2 - vamos carregar um banco de dado que contempla diversas imagens. O TensorFlow já disponibiliza bancos de imagens nativamente. No nosso caso, utilizaremos o fashion mnist."
      ],
      "metadata": {
        "id": "yX9_rpquMNu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "I8lYmvueMuca"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 3: vamos chamar a função \"load_data()\" do objeto mnist para carregar os dados de treinamento e teste. A função \"load_data()\" já separa os dados para cada categoria."
      ],
      "metadata": {
        "id": "n_YjPlxcNkPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images, training_labels), (test_images,test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "yD37N-02N72P"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 4: uma vez que as imagen foram carregadas, vamos verificar quantidade de imagens separadas para treinamento e quantidade separada para testes."
      ],
      "metadata": {
        "id": "ZvQWPhMkOELc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de imagens aeparadas para treinamento:\", len(training_images))\n",
        "print(\"Quantidade de imagens aeparadas para teste:\", len(test_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2hwBln9OTf-",
        "outputId": "b6615246-14f1-4df3-8d6d-c3b3c3c99b48"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de imagens aeparadas para treinamento: 60000\n",
            "Quantidade de imagens aeparadas para teste: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 5: vamos analisar algumas imagens com os respectivos labels para entendermos melhor como a máquina deduz o tipo de imagem."
      ],
      "metadata": {
        "id": "eXH_pA2kOkxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "print(training_images[30000])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[30000])\n",
        "\n",
        "print(\"label correspondente:\", training_labels[30000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "xQbGRFarO0v-",
        "outputId": "9c9721be-8be4-483f-a96d-7ee909433b7b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0 118 204 181 175 213 199 168 197 111   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 173 225 185 179 225 158 142 227 173   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 170 229 226 226 233 151 167 234 158   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 194 222 212 226 222 240 218 230 163   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 198 222 210 207 211 207 208 231 147   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 188 220 209 210 211 215 208 230 144   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 183 232 214 220 212 220 213 239 158   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 183 232 217 216 215 219 216 238 160   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 185 231 218 221 215 218 214 238 170   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 188 233 215 220 219 219 216 238 169   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 169 240 219 221 222 228 214 243 114   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 128 255 214 218 206 205 225 233  53   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 200 229 218 221 219 211 217 228 204   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  34 230 214 217 216 218 218 220 217 231  42   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  94 236 213 219 219 218 215 219 213 234 110   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 167 234 212 218 218 219 212 225 215 231 170   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 200 230 213 216 218 221 211 224 214 228 213   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 192 228 213 216 218 222 213 224 215 221 200   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 202 225 216 214 219 215 219 225 215 219 208   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 215 224 214 215 221 213 217 220 215 216 216   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  26 232 214 218 213 226 212 216 225 215 211 224  27   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  59 234 214 220 214 225 211 213 227 216 212 228  51   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  67 233 214 221 213 227 209 215 228 216 211 228  56   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  92 234 215 219 215 226 208 214 227 215 211 225  42   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 116 236 215 218 211 230 213 212 229 215 211 228  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 140 231 218 221 221 236 204 219 224 221 219 227 132   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 107 200 193 205 194 217 213 218 248 202 172 227 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  21 108 142 146 125 173 141  94 152 154  89   0   0   0   0   0   0   0   0]]\n",
            "label correspondente: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 6: após analisar algumas imagens, vimos que o valor dos pixels variam de 0 a 255. No entanto, para treinar uma rede neural é conveniente que façamos a normalização dos valores de cada pixel, para ficarem entre 0 e 1."
      ],
      "metadata": {
        "id": "ypkFpDszRPqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "#print(training_images[30000])"
      ],
      "metadata": {
        "id": "Ouh9pKABSAQ2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 7:temos dois conjuntos de imagens: um que será utilizado para treinar o modelo e outro que será utilizado para testar o modelo treinado. Esta separação ocorre para evitarmos o overfitting. Dessa forma, vamos utilizar o conjunto de imagens que está na variável training_images para treinar a rede. Depois validaremos a acurácia da rede treinada utilizando o conjunto armazenado na variável test_images.\n",
        "\n",
        "Vamos agora criar o modelo e depois exploraremos alguns conceitos."
      ],
      "metadata": {
        "id": "bpZC4kAtSQuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "                                    ]\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "zCKkoQwgS9rR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comentários relacionados ao modelo criado.\n",
        "\n",
        "**1. Sequential:**  define uma sequência de camadas para a rede neural. É como se fosse criado um cerébro vazio que receberá várias camadas.\n",
        "\n",
        "**2. Flatten:** lembre-se que as imagens do fashion mnist possuem resolução 28 x 28. O Flatten tranforma a matriz em um array unidimensional de 784 posições. O Flatten \"achata\" a matriz.\n",
        "\n",
        "**3. Dense:** função utilizada para criar camadas com neurônios. Pode abranger diferentes funções matemáticas de ativação. **Relu:** se x>0, retorna 1, senão, retorna 0. **Softmax:** retorna a probabilidade, entre 0 e 1, do neurônio ser o resultado final. No nosso caso, temos 10 neurônios na última camada porque o dataset possui 10 tipos de roupas distintas."
      ],
      "metadata": {
        "id": "NABsXTLHVci0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 8: agora que as imagens estão normalizadas e que a arquitetura da rede neural foi criada, é hora de partirmos para o treinamento. Iremos definir a quantidade de épocas na qual a rede será treinada. É importante observar que a cada época é possível medir a acurácia do modelo. A acurácia mede o volume de acerto da rede neural."
      ],
      "metadata": {
        "id": "LvQ-TLOUXKnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QndFbF95Xdko",
        "outputId": "521fcff2-3cd7-4c54-84d3-34fdd14df385"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5010 - accuracy: 0.8242\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3762 - accuracy: 0.8642\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3373 - accuracy: 0.8760\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3138 - accuracy: 0.8850\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2954 - accuracy: 0.8897\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2802 - accuracy: 0.8965\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2687 - accuracy: 0.9004\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2566 - accuracy: 0.9038\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2467 - accuracy: 0.9094\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2378 - accuracy: 0.9107\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78ceb0665ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 9: uma vez que a rede foi treinada, vamos verificar a sua acurácia ao tentar deduzir as roupas armazenadas para teste>"
      ],
      "metadata": {
        "id": "BI26HKT9aY3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG6WwqCxa2sk",
        "outputId": "352d498d-7e20-4312-e6a6-e18c781d9639"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3260115087032318, 0.8878999948501587]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que o modelo foi treinado e vimos que teve uma boa performanca, vamos brincar um pouco com a rede neural. No primeiro teste avaliaremos a probabilidade de saída de cada neurônio."
      ],
      "metadata": {
        "id": "4OhHNi2hbXlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_images[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Mox10S3ZbuVT",
        "outputId": "bee8677c-cec7-4dce-e9ac-f148eadfbcc5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78ceb069d720>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificacao = model.predict(test_images)\n",
        "for i in range(10):\n",
        "  print(\"%.2f\"%classificacao[10,i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGDz_pLZb3Oz",
        "outputId": "50eb418a-0fcd-4055-8d7a-a8640b91bd77"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "0.00\n",
            "0.00\n",
            "0.11\n",
            "0.00\n",
            "0.87\n",
            "0.00\n",
            "0.02\n",
            "0.00\n",
            "0.00\n",
            "0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para melhorar o entendimento, iremos aplicar o mesmo modelo, mas sem normalizar as imagens."
      ],
      "metadata": {
        "id": "vOvMN-SxkbZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "\n",
        "#training_images = training_images/255.0\n",
        "#test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "                                    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOmF193PkqD3",
        "outputId": "c0fe2444-d9a8-4d59-9386-c42500a715cc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 3.1718 - accuracy: 0.6851\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6609 - accuracy: 0.7573\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6215 - accuracy: 0.7785\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5450 - accuracy: 0.8073\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5249 - accuracy: 0.8166\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5078 - accuracy: 0.8268\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4909 - accuracy: 0.8319\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4822 - accuracy: 0.8350\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4849 - accuracy: 0.8355\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4757 - accuracy: 0.8414\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78ceae5acc10>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, vamos fazer uma mesma rede, mas com um número maior de neurônios na camada oculta."
      ],
      "metadata": {
        "id": "3L_Xodd_le-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "                                    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_4oshWLlwjp",
        "outputId": "34ac9b06-46e0-4939-8798-b556d2aa0fb0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4824 - accuracy: 0.8288\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3661 - accuracy: 0.8673\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3276 - accuracy: 0.8797\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3041 - accuracy: 0.8879\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2847 - accuracy: 0.8938\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2690 - accuracy: 0.8998\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2584 - accuracy: 0.9023\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2485 - accuracy: 0.9073\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2357 - accuracy: 0.9119\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2283 - accuracy: 0.9146\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78ceae4b86a0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos fazer uma rede contempla mais de uma camada oculta."
      ],
      "metadata": {
        "id": "ICDS-Oo5mExT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "                                    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WETnMqmZmU0k",
        "outputId": "b256c734-3ca2-4aeb-ddd2-77fa086f50c7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4908 - accuracy: 0.8221\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3678 - accuracy: 0.8661\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3318 - accuracy: 0.8777\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3075 - accuracy: 0.8855\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2921 - accuracy: 0.8909\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2772 - accuracy: 0.8966\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2628 - accuracy: 0.9011\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2543 - accuracy: 0.9033\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2440 - accuracy: 0.9079\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2333 - accuracy: 0.9102\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78cea42c4a90>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ver o que acontece se colocarmos apenas cinco neurônios na camada de saída."
      ],
      "metadata": {
        "id": "nZ8KV_ejmou-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(5, activation = tf.nn.softmax)\n",
        "                                    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Czv_m1Smm3pF",
        "outputId": "33bd69c3-5bdd-41a8-d086-bb2753cd196f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-48-998f319543b4>\", line 18, in <cell line: 18>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nReceived a label value of 9 which is outside the valid range of [0, 5).  Label values: 5 0 2 3 1 6 0 7 9 1 2 7 3 5 9 7 2 7 9 1 3 2 7 9 0 6 5 8 5 1 9 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_941330]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-998f319543b4>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-48-998f319543b4>\", line 18, in <cell line: 18>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nReceived a label value of 9 which is outside the valid range of [0, 5).  Label values: 5 0 2 3 1 6 0 7 9 1 2 7 3 5 9 7 2 7 9 1 3 2 7 9 0 6 5 8 5 1 9 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_941330]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos treinar a rede com mais épocas."
      ],
      "metadata": {
        "id": "0mikXL26m-Im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "                                    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=30)"
      ],
      "metadata": {
        "id": "5zYqEdpMnOHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20109b53-fa51-4126-ad2d-2e2f1be15859"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4957 - accuracy: 0.8253\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3738 - accuracy: 0.8653\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3329 - accuracy: 0.8780\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3096 - accuracy: 0.8865\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2927 - accuracy: 0.8935\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2773 - accuracy: 0.8963\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2662 - accuracy: 0.9010\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2566 - accuracy: 0.9042\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2468 - accuracy: 0.9073\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2363 - accuracy: 0.9113\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2286 - accuracy: 0.9142\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2207 - accuracy: 0.9165\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2151 - accuracy: 0.9194\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2099 - accuracy: 0.9215\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2002 - accuracy: 0.9245\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1943 - accuracy: 0.9271\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1926 - accuracy: 0.9274\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1865 - accuracy: 0.9294\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1818 - accuracy: 0.9313\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1761 - accuracy: 0.9325\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1710 - accuracy: 0.9357\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1685 - accuracy: 0.9363\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1649 - accuracy: 0.9366\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1614 - accuracy: 0.9391\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1577 - accuracy: 0.9406\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1532 - accuracy: 0.9424\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1498 - accuracy: 0.9428\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1471 - accuracy: 0.9448\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1432 - accuracy: 0.9452\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1404 - accuracy: 0.9474\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78ceae4ba6b0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para matar a parte de reconhecimento de imagem, vamos fazer um código digno de venda. Vamos utilizar o callback. O callback é utilizado para interromper o treinamento de uma rede quando determinado valor de acurácia é atingido."
      ],
      "metadata": {
        "id": "yUffrtwCoQIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if (logs.get('accuracy')>0.92):\n",
        "      print(\"\\n Foi atingida a acurácia de 92%  então o treinamento será suspenso.\")\n",
        "      self.model.stop_training=True\n",
        "\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "                                    ]\n",
        ")\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=30, callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "ZG9N8UJjos0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cb3e78-10a6-488d-8cb8-1a9ce0431f53"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4948 - accuracy: 0.8266\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3748 - accuracy: 0.8650\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3358 - accuracy: 0.8770\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3121 - accuracy: 0.8857\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2927 - accuracy: 0.8922\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2783 - accuracy: 0.8968\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2660 - accuracy: 0.9018\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2555 - accuracy: 0.9048\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2446 - accuracy: 0.9086\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2365 - accuracy: 0.9123\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2284 - accuracy: 0.9150\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2203 - accuracy: 0.9179\n",
            "Epoch 13/30\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.9215\n",
            " Foi atingida a acurácia de 92%  então o treinamento será suspenso.\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2127 - accuracy: 0.9218\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78cea0d3ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}